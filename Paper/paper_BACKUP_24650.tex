%http://www.ieee.org/conferences_events/conferences/publishing/templates.html

\documentclass[transmag]{IEEEtran}


\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{bm}  

\usepackage{multirow}

\ifCLASSOPTIONcompsoc
  \usepackage[nocompress]{cite}
\else
  \usepackage{cite}
\fi

\ifCLASSOPTIONcompsoc
\usepackage[caption=false,font=normalsize,labelfon
t=sf,textfont=sf]{subfig}
\else
\usepackage[caption=false,font=footnotesize]{subfi
g}
\fi

\IEEEoverridecommandlockouts                              % This command is only needed if
                                                          % you want to use the \thanks command

\usepackage{xcolor}
\usepackage{etoolbox}

\usepackage{algorithm}
\usepackage{algpseudocode}

\newcommand{\todo}[1]{{\color{red}TODO: {#1}}}
\newcommand{\comment}[1]{{\color{blue}COMMENT: {#1}}}
\def\CPP{C\texttt{++}}

\hyphenation{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Packages used to write code
\usepackage{listings}
\usepackage{color}
 
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 
\lstdefinestyle{mystyle}{
    %backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=none,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\title{$(\mu/\mu,\lambda)-ES$ with Search Path in \CPP}


\author{%
Florence Carton$^{1}$, Alvaro Correia$^{1}$, Gabirel Quéré$^{1}$ and Antonin Raffin$^{1}$%

\thanks{$^{1}$ \'Ecole Nationale Sup\'erieure de Techniques Avanc\'ees (ENSTA-ParisTech), Paris, France}%
}


\maketitle


\begin{abstract}

\end{abstract}

\IEEEpeerreviewmaketitle


\section{Introduction}


The main goal of our work was to implement the algorithm $(\mu/\mu,\lambda)-ES$  with Search Path presented in the paper \cite{algo}. To test and compare our algorithm with other implementations, we used the COCO plateform \cite{coco}. 

In the next section, we introduce the algorithm as it is written in the corresponding paper, then we explain how we implemented it and which results we obtained. 

\section{The algorithm}

The algorithm we implemented is the following : 

\begin{algorithm}
\begin{algorithmic}[1]
\State \textbf{given} $n \in \mathbb{N}$, $\lambda \in \mathbb{N}$, $\mu \approx \lambda/4 \in \mathbb{N}$,  $c_{\sigma} \approx \sqrt{\mu /(n+\mu)}$, $ d \approx 1 + \sqrt{\mu/n}$, $d_i \approx 3n$
\State \textbf{initialize} $\bm{x} \in \mathbb{R}^n $, $\bm{\sigma} \in \mathbb{R}^n _+ $, $\bm{s_{\sigma}} =\bm{0}$
\While{not happy}
	\For{$ k \in \{1, ..., \lambda\} $}
    	\State $\bm{z_k} = \mathcal{N}(\bm{0}, \bm{I})$  iid for each k
    	\State $ \bm{x_k} = \bm{x} + \bm{\sigma} \circ \bm{z_k}$
	\EndFor
    \State $\mathcal{P} \leftarrow sel\_\mu\_best(\{\bm{x_k}, \bm{z_k}, f(\bm{x_k})|1\leq k \leq \lambda \})$ recombination and parent update
    \State $\bm{s_{\sigma}} \leftarrow (1 - c_{\sigma})\bm{s_{\sigma}} + \sqrt{c_{\sigma}(2-c_{\sigma})}\frac{\sqrt{\mu}}{\mu}\sum_{\bm{z_k}\in \mathcal{P}}\bm{z_k} $
    \State $\bm{\sigma} \leftarrow \bm{\sigma} \circ exp^{1/d_i}(\frac{|\bm{s_{\sigma}}|}{\mathbb{E}|\mathcal{N}(0,1)|}-\bm{1}) \times exp^{c_{\sigma}/d}(\frac{||\bm{s_{\sigma}}||}{\mathbb{E}||\mathcal{N}(\bm{0},\bm{1})||}-1) $
    \State $ \bm{x} = \sum_{x_k \in \mathcal{P}} x_k$
\EndWhile
\end{algorithmic}
 \caption{The $(\mu / \mu, \lambda)$ - ES with Search Path}
\end{algorithm}

In this algorithm, $f$ in the function we want to minimize, $\bm{x}$ its parameters, and $n$ the dimension of $\bm{x}$. $\lambda$ is the number of offsprings and $\mu$ is the number of parents. Therefore the selection function will select the $\mu$ best in the offspring population. The $x_k$ are the offsprings, $s_{\sigma}$ is the search path, $z_k$ are the mutation steps and $\sigma$ the mutation vectors. 

%%%%% IMPLEMENTATION %%%%%
\section{Our implementation}

\subsection{Implementation of the algorithm}
<<<<<<< HEAD
We implemented this algorithm in C/C++, and in this section we present how we implemented it and which choices we made. 
=======

We implemented this algorithm in \CPP, and in this section we present how we implemented it and which choices we made. 
>>>>>>> d0d1396223a8d144c1ca0acf9312782af502e8bf

\subsubsection{Initialization}

Regarding the initialization, the vector $\bm{x}$ is initialized to the center of the domain and every element of the vector $\bm{\sigma}$ (\verb|Sigma[]|) is initialized to one sixth of the domain range. This is the preferred initial condition because it keeps the solution as far as possible from the boundaries of the problem domain. Another option would be to randomly initialize the solution vector, but that could possibly bias the analysis as a random $\bm{x}$ could be already too close to the optimum.

$$x_k = lower bound + \frac{upper bound - lower bound}{2} $$

$$\sigma = \frac{upper bound - lower bound}{6}$$

\subsubsection{Stop criteria}
In the while loop, two stop criteria can be found in our implementation. The first one is the budget, i.e. the number of iterations, and the second one is the 'happy' criterion : the programme will stop if there is no change between two iterations bigger that $10^{-9}$ .

\subsubsection{Selecting the $\mu$ best individuals}
In order to select the $\mu$ best individuals, the value of $f$ is calculated for every $x$ in the population and stored in a vector called \verb|fitnnes[]|. The population is then sorted against this vector, so that the $\mu$ best are positioned at the beginning of $X_k$. 
The first implementation relied on a sorting algorithm by insertion, which incurred in a long run time due to its high computational cost $O(n^2)$. Given the already long processing time necessary to run and benchmark the algorithm, it was important to optimize every part of the code and the naive insertion method was replaced by a Shellsort algorithm. 

\subsection{Tuning the hyperparameters}
The performance of the algorithm relies on two hyperparameters, namely the budget multiplier and the size of the population $\lambda$. To fine tune these parameters, the algorithm was tested with different sets of values and analyzed on the COCO platform.

\section{Analysis of the results}

To analyse the results, we launched our algorithm on the COCO platform : \cite{coco}. The COCO (COmparing Continuous Optimizers) platform provides benchmarks for comparison between optimizing algorithm, and visualizing tools to plot the data.


\section{Conclusion}


\section{Bibliography}

\input{biblio2}

\end{document}


